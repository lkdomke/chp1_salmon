---
title: "Seagrass_biomass_regression_2017"
author: "Lia Domke"
date: "10/21/2019"
output: html_document
editor_options: 
  chunk_output_type: console
---
We're curious to see if there is a relationship between *longest* leaf length to *total* shoot biomass. 
Data available: In 2017 21 sites were surveyed for seagrass. At each site, 8-0.25m^2 quadrats were surveyed and 5 entire shoots (i.e. multiple leaves) were removed and brought back to the lab to be measured (in cm). Each shoot (n = 840) was weighed to get total fresh and dry biomass (in grams) and each leaf on the shoot had its length (cm) and width (cm) measured. 

We are interested in the length of the longest leaf and the dry biomass.

If there is a strong relationship, then I would like to use the linear model from 2017 to predict biomass values based on longest leaf length in 2019.
# Data import
```{r}
eelgrass <- read.csv("../APECS Master repository/APECS Master repo/ALL_DATA/seagrass_biometrics_CLEAN.csv")
```
# Libraries
```{r, echo = FALSE}
library(tidyverse)
library(MASS) 
library(visreg)
library(readxl)
library(ggplot2)
library(cowplot)
```
# Data Cleaning
```{r}
# extract what we're interested in 
str(eelgrass)
eel <- eelgrass %>%
  mutate(shoot_dw = shoot_foil_dw-shoot_foil)  # calculate dry weight
# determin max leaf length
#eel <- eel[c(1:10),]
eel2 <- eel %>% 
  ungroup() %>%
  dplyr::rowwise() %>%
  #dplyr::group_by(site, quadrat, plant) %>%
  dplyr::mutate(mean_length = mean(c(leaf_length1, leaf_length2, leaf_length3, leaf_length4, 
                            leaf_length5, leaf_length6, leaf_length7, leaf_length8, 
                            leaf_length9, leaf_length10), na.rm=TRUE)) %>%
  dplyr::mutate(max_length = max(c(leaf_length1, leaf_length2, leaf_length3, leaf_length4,
                   leaf_length5, leaf_length6, leaf_length7, leaf_length8, leaf_length9, leaf_length10), na.rm=TRUE)) #%>%
 #dplyr::select(c(leaf_length1, leaf_length2, leaf_length3, leaf_length4,
  #                 leaf_length5, leaf_length6, leaf_length7, leaf_length8, leaf_length9, leaf_length10, max_length, mean_length))
str(eel2)
# there are a few error/warning messages because on lines 293 - 295 there are no plants
# continues to L663, L680, L704, L705
# subset only the data that was collected before July (the main part of the growing season)
eel_beforeJuly <- eel2 %>%
  filter(YYYYMMDD < 20170701) # before July

eel_sub <- eel2 # all data
str(eel_sub)
levels(as.factor(eel_sub$YYYYMMDD))
summary(eel_sub)
eel_sub2 <- na.omit(data.frame(eel_sub$shoot_dw, 
                               eel_sub$max_length, 
                               eel_sub$mean_length, 
                               eel_sub$shoot_mass_fw))
names(eel_sub2) <- c("shoot_dw", "max_length", "mean_length", "shoot_mass_fw")

summary(eel_beforeJuly)
eel_bJuly2 <- na.omit(data.frame(eel_beforeJuly$shoot_dw,
                               eel_beforeJuly$max_length,
                               eel_beforeJuly$mean_length,
                               eel_beforeJuly$shoot_mass_fw))
names(eel_bJuly2) <- c("shoot_dw", "max_length", "mean_length", "shoot_mass_fw")
```

# Look at data
```{r}
plot(eel_sub2$max_length, eel_sub2$shoot_dw)
# Looks like the variance in shoot dw might be increasing with the the length (mm) of the longest blade. 
plot(eel_sub2$mean_length, eel_sub2$shoot_dw)
plot(eel_sub2$max_length, eel_sub2$shoot_mass_fw)
# not as tight as a correlation
cor(eel_sub2$max_length, eel_sub2$shoot_dw, use = "complete.obs")
cor(eel_sub2$mean_length, eel_sub2$shoot_dw, use = "complete.obs")
cor(eel_sub2$mean_length, eel_sub2$shoot_mass_fw, use = "complete.obs")
# stronger positive linear relationship with max length than average length (makes sense)
par(mfrow=c(1,2))
boxplot(eel_sub2$max_length)
boxplot(eel_sub2$shoot_dw)
# Looks like both varibles may have some outliers, in particular the shoot dry weight. 

par(mfrow=c(1,2))
plot(density(eel_sub2$max_length), ylab = "Frequency")
plot(density(eel_sub2$shoot_dw, na.rm = T), ylab = "Frequency")

hist(eel_sub2$max_length)
# max length looks pretty normal with some slight right? skew
hist(eel_sub2$shoot_dw)
range(eel_sub2$shoot_dw)
# heavily right skewed does log make it look better?
hist(log(eel_sub2$shoot_dw))
# skews it the other way... 


# lets write out the appropriately cleaned 2017 eelgrass data so we can quickly use it to convert eelgrass length to biomass in the future
#write.csv(eel_sub2, file = "Data/eelgrass_conversions_for_lm_2017")
```

# Linear models
## All Data
12/7/20 removed july filter## data only before july

```{r}

dat <- na.omit(data.frame(eel_sub2$shoot_dw, eel_sub2$max_length))
names(dat) <- c("dw", "max_length")
range(dat$dw)

plot(dat$dw, dat$max_length)
# Lets fit an untransformed linear model 
fit.lm <- lm(dw ~ max_length, data = dat)
par(mfrow=c(2,2))
plot(fit.lm, which = 1:4)
# looks like there might be some funky stuff happening with the residuals -- maybe an increase in variance along the fitted values. And the QQ plot looks real gross with some concavity (i.e. skewness) and some possible outliers. The cooks plot makes it look like there case numbers (171, 230, 498) could be influencial outliers. Some of this is consisten with the histogram of the data (see above)
summary(fit.lm)
AIC(fit.lm); BIC(fit.lm)
# looks like max length is significantly different than 0
# Has an adjusted r2 of 69%... pretty good for ecology. Model is significant, coefficients for the model are not equal to zero (p value =~0)
library(e1071)
skewness(dat$dw)
skewness(dat$max_length)
# the response variable is skewed.... highly skewed

e <- residuals(fit.lm)
shapiro.test(e)
n <- length(dat$dw)

ggplot(dat, aes(x = max_length, y = dw)) + geom_point() + theme_classic() +
  geom_smooth(method = "lm", se = TRUE)


# Does a boxcox indicate a transformation is necessary? 
library(MASS)
boxcox(fit.lm)
boxcox(fit.lm, lambda=seq(from=0, to=0.6, by=.01)) 
# Umm of like square root?
# Could also try a log



hist(dat$dw^0.5)
y.2 <- dat$y^(0.5)
# looks way better with a fourth root transformation, normal distribution
fit2 <- lm(dw^(0.5) ~ max_length, data = dat)
plot(fit2)
# looks a lot better, homoscedascity is good, qq plot tails are a little weird, still some outliers
summary(fit2)
# r squared is better, model is still significant
plot(dat$max_length, dat$dw^(0.5))

# Plot the square root transformed data
lm_eqn <- function(dat){
    m <- fit2;
    eq <- substitute(italic(sqrt(y)) == a + b %.% italic(x)*","~~italic(r)^2~"="~r2, 
         list(a = format(unname(coef(m)[1]), digits = 2),
              b = format(unname(coef(m)[2]), digits = 2),
             r2 = format(summary(m)$r.squared, digits = 3)))
    as.character(as.expression(eq));
}
ggplot(dat, aes(x = max_length, y = dw^(0.5))) + 
  geom_point() + 
  geom_smooth(method = "lm", se = TRUE, level = 0.95) + 
  geom_text(x = 25, y = 0.8, label = lm_eqn(dat), parse = TRUE, 
            check_overlap = TRUE) + 
  theme_classic()


# Compare to a logtransformed model (easier to understand)

fit3 <- lm(log(dw) ~ max_length, data = dat)
plot(fit3)
summary(fit3)
hist(log(dat$dw))

plot(dat$max_length, log(dat$dw))

# log-log transformation
lm2 <- lm(log(shoot_dw) ~ log(max_length), data = eel_sub2)
summary(lm2)
par(mfrow=c(2,2))
plot(lm2, which = 1:4) # some issues but voerall looks really nice

# plot the log-log transformed data with linear model 
lm_eqn <- function(dat){
    m <- lm2;
    eq <- substitute(italic(log(y)) == a + b %.% italic(log(x))*","~~italic(r)^2~"="~r2, 
         list(a = format(unname(coef(m)[1]), digits = 2),
              b = format(unname(coef(m)[2]), digits = 2),
             r2 = format(summary(m)$r.squared, digits = 3)))
    as.character(as.expression(eq));
}
ggplot(dat, aes(x = log(max_length), y = log(dw))) + 
  geom_point() + #geom_smooth(method = "lm", se = TRUE, level = 0.95) + 
  #geom_text(x = 2.5, y = -0.5, label = lm_eqn(dat), parse = TRUE, check_overlap = TRUE) + 
  theme_classic() 

visreg(lm2, gg = T)
visreg(lm2, gg = T, scale = "response")

ggplot(data=eel_sub2, aes(lm2$residuals)) +
geom_histogram(color = "black", fill = "purple4") +
theme(panel.background = element_rect(fill = "white"),
axis.line.x=element_line(),
axis.line.y=element_line()) +
ggtitle("Histogram for Model Residuals") # damns those residuals are NICE. Pretty symmetrical around 0 -- the model fits teh data pretty well 

ggplot(data = dat, aes(x = log(max_length), y = log(dw))) +
geom_point() +
stat_smooth(method = "lm", col = "dodgerblue3") +
theme(panel.background = element_rect(fill = "white"),
axis.line.x=element_line(),
axis.line.y=element_line()) +
ggtitle("Linear Model Fitted to Data")
```
## Before July
Which fit of linear model is better?
We know that the log-log relationship is better so lets try that and then compare the two model types
```{r}
dat2 <- na.omit(data.frame(eel_bJuly2$shoot_dw, eel_bJuly2$max_length))
names(dat2) <- c("dw", "max_length")

lm4 <- lm(log(dw) ~ log(max_length), data = dat2)
summary(lm4)

```

# Use selected linear model to predict 2019 biomass data
## Import 2019 data
The data for 2019: is set up in a 3 sheet excel spreadsheets. quadrat_ID in hab_qrt is unique for *every*
quadrat that was done in summer 2019. Use the quadrat_ID to connect to the other sheets (hab_lng and hab_wgt). Hab_lng has all the individual lengths for all measured plants (in mm) (for eelgrass its 15 blades from each quadrat/site. For kelp its up to 3 of each species collected from the site). Hab_wgt has the biomass weights for individual species biomass by bag

For this purpose we are interested in only the length data but need to use the quadrat sheet to make sure we only are looking at the eelgrass sites
newest version of data is : RAW_10-22-19
```{r}
hab_qrt <- read.csv(url("https://knb.ecoinformatics.org/knb/d1/mn/v2/object/urn%3Auuid%3A33a4f3b6-ad30-494d-a0bf-861fe86d729e"), stringsAsFactors = FALSE, header = TRUE)

hab_lng <- read.csv(url("https://knb.ecoinformatics.org/knb/d1/mn/v2/object/urn%3Auuid%3Af7c43f66-6800-49b0-9b3d-43e8e39abcd0"), stringsAsFactors=FALSE, header=TRUE)

#hab_wgt <- read.csv(url("https://knb.ecoinformatics.org/knb/d1/mn/v2/object/urn%3Auuid%3A3b4ab5b8-c023-486f-8a89-7464b9bccf7a"))

loc <- read.csv(url("https://knb.ecoinformatics.org/knb/d1/mn/v2/object/urn%3Auuid%3Ac9c99ce9-fbdd-4879-a2c9-c90448cdba7b"), stringsAsFactors = FALSE, header = TRUE)


```
## include 2022 too
```{r}
# read in 2022
qrt22 <- read.csv("../APECS_DM/Data/Habitat_data/hab_quadrat_2022_clean_3-14-23.csv")
lng22 <- read.csv("../APECS_DM/Data/Habitat_data/hab_length_2022_clean_3-14-23.csv")

# read in 2021
lng21 <- read.csv("../APECS_DM/Data/Habitat_data/hab_length_2021_measuredphyllo_3-9-23.csv")
qrt21 <- read.csv("../APECS_DM/Data/Habitat_data/hab_quadrat_2021_clean_10-11-22.csv")
```

## Data cleaning
```{r}
# adjust the site names in qrt data so that we can combine with 
hab_qrt$site <- as.factor(hab_qrt$site)
levels(hab_qrt$site)[levels(hab_qrt$site)=="Goats mouth inlet"]<-"Goat Mouth Inlet"
levels(hab_qrt$site)[levels(hab_qrt$site)=="Naukati Bay"]<-"Naukati"
levels(hab_qrt$site)[levels(hab_qrt$site)=="South Wadleigh Island"]<-"South Wadleigh"
levels(hab_qrt$site)[levels(hab_qrt$site)=="Guktu Bay"]<-"Guktu"
levels(hab_qrt$site)[levels(hab_qrt$site)=="North Fish Egg Island"]<-"North Fish Egg"
levels(hab_qrt$site)[levels(hab_qrt$site)=="North Fish Egg - kelp"]<-"North Fish Egg-Kelp"
levels(hab_qrt$site)[levels(hab_qrt$site)=="Natzuhini Bay"]<-"Natzuhini"
levels(hab_qrt$site)[levels(hab_qrt$site)=="Kaguk Cove"]<-"Kaguk "
levels(hab_qrt$site)[levels(hab_qrt$site)=="Farallon Bay"]<-"Farallon"
levels(hab_qrt$site)[levels(hab_qrt$site)=="Chusini Cove"]<-"Chusini-Kladein Flat"
levels(hab_qrt$site)[levels(hab_qrt$site)=="South Fish Egg Island"]<-"South Fish Egg"
levels(hab_qrt$site)[levels(hab_qrt$site)=="Baker Island - kelp"]<-"Baker Island - kelp "
hab_qrt$site <- as.character(hab_qrt$site)

hab_qrt <- left_join(hab_qrt, loc, by = c("site" = "site_2019", "habitat" = "habitat")) %>%
  dplyr::select(-c(siteID_NOAA, site_2017, site_2018, place_name, study, latitude, longitude,
                   freshwater, sediment_description, general_description)) %>%
  filter(habitat == "eelgrass")
```

We want only the eelgrass sites and need to convert the length measurements (in mm) to cm 
```{r}
glimpse(hab_qrt)

# Want to only extract the quadrat numbers that were used to sample eelgrass sites
eel_qrts <- na.omit(ifelse(hab_qrt$habitat == "eelgrass", paste(hab_qrt$quadrat_ID), NA))
# subset the length data by quadrat at an eelgrass site
lng_sub <- subset(hab_lng, quadrat_ID %in% eel_qrts)
levels(as.factor(lng_sub$species)) # only Z. marina, awesome! 

lng_sub <- lng_sub %>%
  mutate(length_cm = length/10)

#### for 2022 too 
eel_qrts22 <- qrt22 %>%
  filter(habitat_quadrat == "eel") %>%
  dplyr::select(c(bay_id, quadrat_ID)) # we're actually going to remove this cause sometimes we got eelgrass in non eel quadrats and we want those weights too

eel.lngs22 <- lng22 %>% #subset(lng22, quadrat_ID %in% eel_qrts22$quadrat_ID) %>% # subset lng22 by the quadrats where eelgrass was calc
  filter(species == "Zostera marina")  %>%# some of the quadrats have a combination of phyllospadix and zostera
  mutate(length_cm = length_mm/10)

#### for 2021
qrt21 %>%
  filter(habitat_quadrat == "eelgrass") %>%
  dplyr::select(c(bay_id, quadrat_ID))

eel.lng21 <- lng21 %>%
  filter(species == "Zostera marina") %>%
  mutate(length_cm = length_mm/10)
```

## Predict based on linear models
### all data (lm2)
```{r}
summary(lm2)
# formula :
#   log (y) = beta0 + beta1 * log (x) 
#   log (dw) = -7.67 + 1.55 * log (max_length) 
# create a new dataframe with just the leaf lengths from 2019
newx <- data.frame(max_length = as.numeric(lng_sub$length_cm))

# use the log-log linear model (equation above) to calculate the dry mass of the shoot with 95% CI 
# make sure to exp() the values because its a log-log relationship
pr.lm <- exp(predict(lm2, newdata = newx, interval = "confidence", level = 0.95))

pr.exp <- data.frame(predict(lm2, newdata = newx, interval = "confidence", level = 0.95))


# okay because we had to log-transform the data in order to make it fit 
# normality it requires a log-normal transformation which is equal to the 
# squared(standard deviation of the residuals)/2, so variance/2
correction <- (sd(lm2$residuals)^2)/2
corr.fit <- exp((pr.exp$fit + correction)) # you add it to the fitted LOG SPACE and then exponentiate it
corr.lwr <- exp(pr.exp$lwr + correction) # also needs to be done to the confidence intervals
corr.upr <- exp(pr.exp$upr + correction)

# graph these new predicted values
# create data.frame first
newdata <- cbind(lng_sub, pr.lm)
newdata.corr <- cbind(lng_sub, corr.fit) %>%
  cbind(corr.lwr) %>%
  cbind(corr.upr)
ggplot() + 
  geom_point(data = newdata, aes(x = length_cm, y = fit), color = "green") + 
  theme_classic() + 
  geom_point(data = newdata.corr, aes(x = length_cm, y = corr.fit))
  geom_smooth(method = "lm", data = newdata, aes(x = )) # isn't plotting the lm


```


#### Estimate total biomass (lm2)
```{r}
str(newdata)
str(hab_qrt)
hab_qrt$density <- as.numeric(hab_qrt$density)
hab_qrt$flowering_shoots <- as.numeric(hab_qrt$flowering_shoots)

# Want to only extract the quadrat numbers that were used to sample eelgrass sites
dsty <- hab_qrt %>%
  filter(habitat == 'eelgrass') %>%
  mutate(density_m2 = (density)*4, 
         density_0.25msq = density) %>%
  mutate(flowering_m2 = (flowering_shoots)*4, 
         flowering_0.25msq = flowering_shoots)
dsty <- dplyr::select(dsty, quadrat_ID, site, date, YYYYMMDD, 
                      habitat, quadrat, total_biomass, density_m2, flowering_m2, 
                      bay_code, bay_sample, notes, density_0.25msq, flowering_0.25msq)

# calculate average biomass for 15 shoots for each quadrat
#require(dplyr)
#df <- newdata %>%
#  group_by(quadrat_ID) %>%
#  mutate(avg_biomass = mean(fit))
#df1 <- df %>%
#  dplyr::select(quadrat_ID, avg_biomass) %>%
#  distinct()

df <- newdata.corr %>%
  group_by(quadrat_ID) %>%
  mutate(avg_biomass = mean(corr.fit))
df1 <- df %>%
  dplyr::select(quadrat_ID, avg_biomass) %>%
  distinct()

# need to add back in site information

df2 <- left_join(df1, dsty, by = "quadrat_ID")
df3 <- left_join(df2, hab_qrt[,c("quadrat_ID","site")], by = "quadrat_ID") # want quadratID:site
#write.csv(df3, "../APECS Master repository/APECS Master repo/ALL_DATA/seagrass_biomass_conversions_baycodes_correction_11-17-23.csv") 
```

### Before July
### all data (lm4)
```{r}
summary(lm4)
# formula :
#   log (y) = beta0 + beta1 * log (x) 
#   log (dw) = -7.78 + 1.57 * log (max_length) 
# create a new dataframe with just the leaf lengths from 2019
newx_lm4 <- data.frame(max_length = as.numeric(lng_sub$length_cm))
newx21_lm4 <- data.frame(max_length = as.numeric(eel.lng21$length_cm))
newx22_lm4 <- data.frame(max_length = as.numeric(eel.lngs22$length_cm))
# use the log-log linear model (equation above) to calculate the dry mass of the shoot with 95% CI 
# make sure to exp() the values because its a log-log relationship
pr.lm4 <- exp(predict(lm4, newdata = newx_lm4, interval = "confidence", level = 0.95))
pr.lm4.21 <- exp(predict(lm4, newdata = newx21_lm4, interval = "confidence", level = 0.95))
pr.lm4.22 <- exp(predict(lm4, newdata = newx22_lm4, interval = "confidence", level = 0.95))

# again need to correct for the back transformation to median instead of mean
ex.pr.lm4 <- data.frame(predict(lm4, newdata = newx_lm4, interval = "confidence", level = 0.95))
ex.pr.lm4.21 <- data.frame(predict(lm4, newdata = newx21_lm4, interval = "confidence", level = 0.95))
ex.pr.lm4.22 <- data.frame(predict(lm4, newdata = newx22_lm4, interval = "confidence", level = 0.95))
# okay because we had to log-transform the data in order to make it fit 
# normality it requires a log-normal transformation which is equal to the 
# squared(standard deviation of the residuals)/2, so variance/2
correction2 <- (sd(lm4$residuals)^2)/2
corr.fit <- exp((ex.pr.lm4$fit + correction2)) # you add it to the fitted LOG SPACE and then exp it
corr.lwr <- exp((ex.pr.lm4$lwr + correction2)) # also needs to be done to the confidence intervals
corr.upr <- exp((ex.pr.lm4$upr + correction2))
corr <-cbind(corr.fit, corr.lwr) %>%
  cbind(corr.upr)

correction2 <- (sd(lm4$residuals)^2)/2
corr.fit21 <- exp((ex.pr.lm4.21$fit + correction2)) # you add it to the fitted LOG SPACE and then exp it
corr.lwr21 <- exp((ex.pr.lm4.21$lwr + correction2)) # also needs to be done to the confidence intervals
corr.upr21 <- exp((ex.pr.lm4.21$upr + correction2))
corr21 <-cbind(corr.fit21, corr.lwr21) %>%
  cbind(corr.upr21)

corr.fit22 <- exp((ex.pr.lm4.22$fit + correction2)) # you add it to the fitted LOG SPACE and then exp it
corr.lwr22 <- exp((ex.pr.lm4.22$lwr + correction2)) # also needs to be done to the confidence intervals
corr.upr22 <- exp((ex.pr.lm4.22$upr + correction2))
corr22 <- cbind(corr.fit22, corr.lwr22) %>%
  cbind(corr.upr22)

# graph these new predicted values
# create data.frame first
newdata_lm4.corr <- cbind(lng_sub, corr) %>%
  dplyr::rename(lwr = corr.lwr,
         upr = corr.upr,
         fit = corr.fit)
#newdata_lm4 <- cbind(lng_sub, pr.lm4)
ggplot(newdata_lm4.corr, aes(x = log(length_cm), y = fit)) + geom_point() + theme_classic() + geom_smooth(method = "lm")

# these are the NEW (10/23) CORRECTED VALUES
newdata_lm422 <- cbind(eel.lngs22, corr22) %>%
  dplyr::rename(lwr = corr.lwr22,
         upr = corr.upr22,
         fit = corr.fit22)

newdata_lm421 <- cbind(eel.lng21, corr21) %>%
  dplyr::rename(lwr = corr.lwr21,
         upr = corr.upr21,
         fit = corr.fit21)
# because this gives the lng + CI of the individual blades for eelgrass, we're going to rbind it with the rest of the lngths and then read it out
lng22.red <- lng22 %>%
  anti_join(newdata_lm422) %>%
  mutate(length_cm = length_mm/10, 
         fit = NA,
         lwr = NA,
         upr = NA)

lng21.red <- lng21 %>%
  anti_join(newdata_lm421) %>%
  mutate(length_cm = length_mm/10,
         fit = NA,
         lwr = NA,
         upr = NA)

lng22.biomass <- rbind(lng22.red, newdata_lm422)
lng21.biomass <- rbind(lng21.red, newdata_lm421)

# this is just for 2021 and 2022 (see below for writing out 2019)
#write.csv(lng21.biomass, "Data/hab_length_2021_Zosbiomass_10-18-23.csv")
#write.csv(lng22.biomass, "Data/hab_length_2022_Zosbiomass_10-18-23.csv")
```


#### Estimate total biomass (lm2)
```{r}
str(newdata_lm4.corr)
str(newdata_lm4)
str(hab_qrt)
hab_qrt$density <- as.numeric(hab_qrt$density)
hab_qrt$flowering_shoots <- as.numeric(hab_qrt$flowering_shoots)
# Want to only extract the quadrat numbers that were used to sample eelgrass sites
dsty <- hab_qrt %>%
  filter(habitat == 'eelgrass') %>%
  mutate(density_m2 = (density)*4) %>%
  mutate(flowering_m2 = (flowering_shoots)*4) %>%
  dplyr::select(c(quadrat_ID, density, flowering_shoots, bay_code, 
                  bay_sample, density_m2, flowering_m2))
#dsty <- dsty[,c(1,8,9,11,12)]

# calculate average biomass for 15 shoots for each quadrat
require(dplyr)
df_lm4.corr <- newdata_lm4.corr %>%
  dplyr::group_by(quadrat_ID) %>%
  dplyr::mutate(avg_biomass = mean(fit))
df1_lm4 <- df_lm4.corr %>%
  dplyr::select(quadrat_ID, avg_biomass) %>%
  distinct()

# need to add back in site information

df2_lm4 <- left_join(df1_lm4, dsty, by = "quadrat_ID")
df3_lm4 <- left_join(df2_lm4, hab_qrt[,c("quadrat_ID", "site")], by = "quadrat_ID")
#write.csv(df3_lm4, "../APECS Master repository/APECS Master repo/ALL_DATA/seagrass_biomass_conversions_corrected_10-20-23.csv")

range(df3_lm4$avg_biomass) # 0.00179 - 0.004, 0.02 - 0.5 CORRECTED 0.027-0.559
```

# Look at variation in biomass between years by site
## 2017
``` {r}
eel17 <- read.csv(url("https://knb.ecoinformatics.org/knb/d1/mn/v2/object/urn%3Auuid%3A5e946e41-4f5f-4499-9969-766f01113971"),
                  stringsAsFactors = FALSE, header = TRUE) # density data

eel_biom17 <- eel_sub %>%
  group_by(site, quadrat) %>%
  mutate(avg_biom_per_quad = mean(shoot_dw)) %>%
  dplyr::select(site:plant, avg_biom_per_quad, mean_length, 
                max_length, shoot_dw,rhi_length:notes)

eel_biom_dens17 <- eel_biom17 %>%
  dplyr::select(site:avg_biom_per_quad, -plant) %>%
  distinct() %>% 
  left_join(eel17, by = c("site", "quadrat")) %>%
  mutate(total_shoots_0.25msq = eelgrass_shoots_0.25msq + flowering_shoots_0.25msq) %>%
  mutate(shoots_1msq = total_shoots_0.25msq * 4) %>%
  dplyr::select(site:YYYYMMDD.y, depth_m,eelgrass_shoots_0.25msq:shoots_1msq, -notes) %>%
  mutate(biom_per_quad_0.25msq = avg_biom_per_quad * total_shoots_0.25msq) %>%
  mutate(biom_msq = biom_per_quad_0.25msq * 4)

biomass_var_2017 <- eel_biom_dens17 %>%
  ggplot() + 
  geom_boxplot(aes(y = biom_msq, x = site)) +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))

biomass_var_2017

# write.csv(eel_biom_dens17, "eelgrass_biom_density_2017.csv")
```

```{r}
biomass_var_2019 <- df3_lm4 %>%
  mutate(biom_msq = avg_biomass * density_m2) %>%
  ggplot() +
  geom_boxplot(aes(y = biom_msq, x = site)) +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))

biomass_var_2019_alldat <- df3 %>%
  mutate(biom_msq = avg_biomass * density_m2) %>%
  ggplot() +
  geom_boxplot(aes(y = biom_msq, x = site)) +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))

plot_grid(biomass_var_2019, biomass_var_2019_alldat, 
          nrow=1, ncol=2)
```

compare 2017 and 2019 biomass
```{r}
plot_grid(biomass_var_2017, biomass_var_2019_alldat, 
          nrow=1, ncol =2 )
```

